---
layout: post
title: 使用 Phoenix-4.11.0连接 Hbase 集群 ,并使用 JDBC 查询测试
categories: HBase Phoenix
description: 使用 Phoenix-4.11.0连接 Hbase 集群 ,并使用 JDBC 查询测试
keywords: HBase Phoenix
---

# 什么是 Phoenix ？

Apache Phoenix 是运行在Hbase之上的高性能关系型数据库，通过Phoenix可以像使用jdbc访问关系型数据库一样访问hbase。  

Phoenix，操作的表以及数据存储在hbase上。phoenix只需要和hbase进行表关联。然后在用工具进行一些读写操作。  

可以把Phoenix 只看成一种代替Hbase语法的工具。虽然Java可以用jdbc来连接phoenix，然后操作hbase，但是在生产环境中，不可以用OLTP中。  

phoenix在查询hbase时，虽然做了一些优化，但是延迟还是不小。所以依然用在OLAT中，在将结果返回存储下来。  

# 准备工作

## 环境

```sh
JDK:1.8  
Hadoop Release:2.7.4  
centos:7.3  

node1（master）  主机: 192.168.252.121  
node2（salve）  从机: 192.168.252.122  
node3（salve）  从机: 192.168.252.123  

node4（ZooKeeper）  主机: 192.168.252.124
```

## 依赖环境

**Hadoop**

[Hadoop-2.7.4 集群快速搭建](https://segmentfault.com/a/1190000011266759)

**HBase**

[HBase-1.3.1 集群搭建](https://segmentfault.com/a/1190000011277511)

# 安装

## 下载解压

在 ndoe1 上操作
```sh
su hadoop
cd /home/hadoop/
wget https://mirrors.tuna.tsinghua.edu.cn/apache/phoenix/apache-phoenix-4.11.0-HBase-1.3/bin/apache-phoenix-4.11.0-HBase-1.3-bin.tar.gz
tar -zxvf apache-phoenix-4.11.0-HBase-1.3-bin.tar.gz
mv apache-phoenix-4.11.0-HBase-1.3-bin phoenix-4.11.0
```

## 配置 Phoenix

### 复制 JAR

进入 `/phoenix-4.11.0` 文件目录

```sh
cd /home/hadoop/phoenix-4.11.0/
```

把两个 jar 包 `phoenix-4.11.0-HBase-1.3-client.jar`,`phoenix-core-4.11.0-HBase-1.3.jar` 拷贝至 `Hbase`的`/lib`文件夹。

```sh
cp phoenix-4.11.0-HBase-1.3-client.jar /home/hadoop/hbase-1.3.1/lib/
cp phoenix-core-4.11.0-HBase-1.3.jar /home/hadoop/hbase-1.3.1/lib/
```

### 复制 base-site.xml

进入 Hbase `conf`配置目录

```sh
cd /home/hadoop/hbase-1.3.1/conf/
```

把 Hbase 的配置文件 `base-site.xml`拷贝至 `Phoenix` 根目录中的 `/bin` 文件夹下到此就完成了配置。

```sh
cp hbase-site.xml /home/hadoop/phoenix-4.11.0/bin
```

## 配置集群

复制节点

将 phoenix-4.11.0文件夹重打包后复制到其他子节点

```sh
cd /home/hadoop/
```

```sh
tar zcvf phoenix.tar.gz phoenix-4.11.0
scp phoenix.tar.gz hadoop@node2:/home/hadoop/
scp phoenix.tar.gz hadoop@node3:/home/hadoop/
```

在 node2，node3 节点解压
```sh
cd /home/hadoop/
tar -zxvf phoenix.tar.gz
```

进入 node2，node3 节点 `phoenix-4.11.0` 文件目录

```sh
cd /home/hadoop/phoenix-4.11.0/
```

把两个 jar 包 `phoenix-4.11.0-HBase-1.3-client.jar`,`phoenix-core-4.11.0-HBase-1.3.jar` 拷贝至 `Hbase`的`/lib`文件夹。

```sh
cp phoenix-4.11.0-HBase-1.3-client.jar /home/hadoop/hbase-1.3.1/lib/
cp phoenix-core-4.11.0-HBase-1.3.jar /home/hadoop/hbase-1.3.1/lib/
```

## 启动

```sh
cd /home/hadoop/phoenix-4.11.0/bin
```

```sh
./sqlline.py 192.168.252.124:2181
```

如果看到如下信息，证明，配置没毛病

```sh
Setting property: [incremental, false]
Setting property: [isolation, TRANSACTION_READ_COMMITTED]
issuing: !connect jdbc:phoenix:node4:2181 none none org.apache.phoenix.jdbc.PhoenixDriver
Connecting to jdbc:phoenix:node4:2181
17/09/21 13:58:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Connected to: Phoenix (version 4.11)
Driver: PhoenixEmbeddedDriver (version 4.11)
Autocommit status: true
Transaction isolation: TRANSACTION_READ_COMMITTED
Building list of tables and columns for tab-completion (set fastconnect to true to skip)...
92/92 (100%) Done
Done
sqlline version 1.2.0
0: jdbc:phoenix:node4:2181>
```

## 命令行测试

### ​创建表

```sh
create table test (mykey integer not null primary key, mycolumn varchar);
```
### ​增加，修改表数据

```sh
upsert into test values (1,'Hello');
upsert into test values (2,'www.ymq.io');
```

### ​查询表数据


```sh
select * from test;
```

响应

```sh
+--------+-------------+
| MYKEY  |  MYCOLUMN   |
+--------+-------------+
| 1      | Hello       |
| 2      | www.ymq.io  |
+--------+-------------+
2 rows selected (0.083 seconds)
```

### ​ 删除表

```sh
drop table test;
```

## JDBC 测试


[github-源码：https://github.com/souyunku/ymq-example/tree/master/ymq-example/ymq-apache-phoenix](https://github.com/souyunku/ymq-example/tree/master/ymq-example/ymq-apache-phoenix)

```sh
public static void main(String[] args) throws Throwable {

	try {

		Class.forName("org.apache.phoenix.jdbc.PhoenixDriver");

		//这里配置zookeeper的地址，可单个，多个(用","分隔)可以是域名或者ip

		String url = "jdbc:phoenix:node4:2181";

		Connection conn = DriverManager.getConnection(url);

		Statement statement = conn.createStatement();

		long time = System.currentTimeMillis();

		ResultSet rs = statement.executeQuery("select * from test");

		while (rs.next()) {
			String myKey = rs.getString("MYKEY");
			String myColumn = rs.getString("MYCOLUMN");

			System.out.println("myKey=" + myKey + "myColumn=" + myColumn);
		}

		long timeUsed = System.currentTimeMillis() - time;

		System.out.println("time " + timeUsed + "mm");

		// 关闭连接
		rs.close();
		statement.close();
		conn.close();

	} catch (Exception e) {
		e.printStackTrace();
	}
}
```

响应

```sh
myKey=1myColumn=Hello
myKey=2myColumn=www.ymq.io
time 127mm
```

**如果有报错，请参考，反正我是没报错** [http://www.cnblogs.com/huxinga/p/6875929.html](http://www.cnblogs.com/huxinga/p/6875929.html)


# Contact

 - 作者：鹏磊  
 - 出处：[http://www.ymq.io](http://www.ymq.io)  
 - 版权归作者所有，转载请注明出处
 - Wechat：关注公众号，搜云库，专注于开发技术的研究与知识分享
 
![关注公众号-搜云库](http://www.ymq.io/images/souyunku.png "搜云库")














