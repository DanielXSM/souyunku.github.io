---
layout: post
title: HBase-1.3.1 集群搭建
categories: HBase
description: HBase-1.3.1 集群搭建
keywords: HBase
---

# 什么是HBase？

HBase是建立在Hadoop文件系统之上的分布式面向列的数据库。它是一个开源项目，是横向扩展的。

HBase是一个数据模型，类似于谷歌的大表设计，可以提供快速随机访问海量结构化数据。它利用了Hadoop的文件系统（HDFS）提供的容错能力。

它是Hadoop的生态系统，提供对数据的随机实时读/写访问，是Hadoop文件系统的一部分。

人们可以直接或通过HBase的存储HDFS数据。使用HBase在HDFS读取消费/随机访问数据。 HBase在Hadoop的文件系统之上，并提供了读写访问。

# 准备工作

## 环境

```sh
JDK:1.8  
Hadoop Release:2.7.4  
centos:7.3  

node1（master）  主机: 192.168.252.121  
node2（salve）  从机: 192.168.252.122  
node3（salve）  从机: 192.168.252.123  

node4（ZooKeeper）  主机: 192.168.252.124
```

## 依赖环境

**Scala**

[Scala-2.13.0 安装及配置](https://segmentfault.com/a/1190000011314775)  

**Hadoop**

[Hadoop-2.7.4 集群快速搭建](https://segmentfault.com/a/1190000011266759)

# 安装

## 下载解压

在 ndoe1 上操作
```sh
su hadoop
cd /home/hadoop/
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/1.3.1/hbase-1.3.1-bin.tar.gz
tar -xzf hbase-1.3.1-bin.tar.gz
```
## 环境变量

如果是对所有的用户都生效就修改`vi /etc/profile` 文件
如果只针对当前用户生效就修改 `vi ~/.bahsrc` 文件

```sh
sudo vi /etc/profile
```

```sh
#Hbase
export PATH=${HBASE_HOME}/bin:$PATH
export HBASE_HOME=/home/hadoop/hbase-1.3.1/
```
使环境变量生效，运行 `source /etc/profile`使`/etc/profile`文件生效

## 配置 HBase

进入HBase配置文件目录

```sh
cd /home/hadoop/hbase-1.3.1/conf/
```

编辑 `hadoop-env.sh` 文件,找到 `JAVA_HOME` 改为 JDK 的安装目录

```sh
vi hbase-env.sh
```

```sh
export JAVA_HOME=/lib/jvm
export HBASE_MANAGES_ZK=false
```

其实HBase里面自带了一个ZooKeeper，而这个属性的值就是是否使用这个自带的ZooKeeper，很显然我这里要使用自己的ZooKeeper，所以修改为false。

### 修改 hbase-site.xml

打开 core-site.xml文件并对其进行编辑，如下图所示。

```sh
vi hbase-site.xml
```

```xml
<configuration>
    <property>
        <name>hbase.rootdir</name>
        <value>hdfs://node1:9000/hbase</value>
    </property>
    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
    </property>
    <property>
        <name>hbase.zookeeper.quorum</name>
        <value>node4:2181</value>
    </property>
</configuration>
```

## 配置集群

### 修改 regionservers 文件

删除`locahost`，添加所有`hbase`节点的主机名

```sh
[root@node1 conf]# cat regionservers 
node2
node3
```

### 复制节点

将 hbase-1.3.1 文件夹重打包后复制到其他子节点

```sh
cd /home/hadoop/

tar zcvf hbase.tar.gz hbase-1.3.1
scp hbase.tar.gz hadoop@node2:/home/hadoop/
scp hbase.tar.gz hadoop@node3:/home/hadoop/
```

在其他子节点 解压
```sh
tar -zxvf hbase.tar.gz
```

# 集群操作

## 启动 Hbase


关闭防火墙
```sh
systemctl stop firewalld.service
```


**确保 Hadoop,ZooKeeper 已经正常启动，执行以下命令**

```sh
cd /home/hadoop/hbase-1.3.1/bin
```

```sh
./start-hbase.sh
```

![][1]
 

## 查看进程服务

查看启动进程,缺少以下任一进程都表示出错

**node1 (master)**

```sh
$ jps
2528 NameNode			#hadoop master进程
2720 SecondaryNameNode
2872 ResourceManager
3357 HMaster			#hbase master进程
3151 JobHistoryServer
```

**node2,node3 (salve)**

```sh
$ jps
2528 NodeManager
2417 DataNode
2687 HRegionServer		#hbase msalve进程
```

**node3 (ZooKeeper)**

```sh
$ jps
2285 QuorumPeerMain		 # ZooKeeper进程 
```

**查看端口占用情况**

```sh
netstat -tnlp | grep java
```

## 停止 Hbase

```sh
cd /home/hadoop/hbase-1.3.1/bin
./stop-hbase.sh
```

或者 jps 查看进程`kill` 掉

[1]: /images/2017/hbase/hbase-maste.png

# Contact

 - 作者：鹏磊  
 - 出处：[http://www.ymq.io](http://www.ymq.io)  
 - Email：[admin@souyunku.com](admin@souyunku.com)  
 - GitHub：[https://github.com/souyunku](https://github.com/souyunku)  
 - Segment Fault：[https://sf.gg/blog/souyunku](https://sf.gg/blog/souyunku)  
 - 版权归作者所有，转载请注明出处
 - Wechat：关注公众号，搜云库，分享技术，分享生活
 
![关注公众号-搜云库](http://www.ymq.io/images/souyunku.png "搜云库")
