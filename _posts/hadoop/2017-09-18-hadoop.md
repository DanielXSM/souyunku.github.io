---
layout: post
title: Hadoop-2.7.4 集群快速搭建
categories: Hadoop
description: Hadoop-2.7.4 集群快速搭建
keywords: Hadoop
---

# 什么是hadoop？


Hadoop是一个由Apache基金会所开发的[分布式系统 ](https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F)基础架构。

用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。

Hadoop实现了一个[分布式文件系统](https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F)（Hadoop Distributed File System），简称HDFS。HDFS有高[容错性](https://baike.baidu.com/item/%E5%AE%B9%E9%94%99%E6%80%A7)的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。

Hadoop的框架最核心的设计就是：[HDFS](https://baike.baidu.com/item/hdfs)和[MapReduce](https://baike.baidu.com/item/MapReduce)。HDFS为海量的数据提供了存储，则[MapReduce](https://baike.baidu.com/item/MapReduce)为海量的数据提供了计算


# 准备工作

## 环境

```sh
JDK:1.8  
Hadoop Release:2.7.4  
centos:7.3  

node1（master）  主机: 192.168.252.121  
node2（slave1）  从机: 192.168.252.122  
node3（slave2）  从机: 192.168.252.123  
```

**安装 JDK**

[CentOs7.3 安装 JDK1.8](https://segmentfault.com/a/1190000010716919)


<<<<<<< HEAD
**SSH 免秘钥**

[CentOs7.3 Hadoop 用户 ssh 免密登录](https://segmentfault.com/a/1190000011264924)


=======
>>>>>>> 2c6f9520789273718e23eb4f918e92b7b04d618b
## 创建用户

建议创建一个单独的用户Hadoop以从Unix文件系统隔离Hadoop文件系统

```sh
$ useradd hadoop
$ passwd hadoop
New password: 
Retype new password: 
```

授权 root 权限,在`root`下面加一条`hadoop`的`hadoop  ALL=(ALL)    ALL`

```sh
$ chmod 777 /etc/sudoers
$ vi /etc/sudoers
root    ALL=(ALL)       ALL
hadoop  ALL=(ALL)       NOPASSWD:ALL
$ pkexec chmod 0440 /etc/sudoers
```

## 免秘钥登录

**SSH 免秘钥**

[CentOs7.3 Hadoop 用户 ssh 免密登录](https://segmentfault.com/a/1190000011264924)


# 安装


## 下载解压

在 ndoe1 上操作
```sh
su hadoop
cd /home/hadoop/
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.4/hadoop-2.7.4.tar.gz
tar -xzf hadoop-2.7.4.tar.gz
```
## 环境变量

如果是对所有的用户都生效就修改`vi /etc/profile` 文件
如果只针对当前用户生效就修改 `vi ~/.bahsrc` 文件

```sh
sudo vi /etc/profile
```

```sh
#hadoop
export PATH=${HADOOP_HOME}/bin:$PATH
export HADOOP_HOME=/home/hadoop/hadoop-2.7.4/
```

使环境变量生效，运行 `source /etc/profile`使`/etc/profile`文件生效

## 配置Hadoop

进入hadoop 配置文件目录

```sh
cd /home/hadoop/hadoop-2.7.4/etc/hadoop/
```

编辑 `hadoop-env.sh` 文件,找到 `JAVA_HOME` 改为 JDK 的安装目录

```sh
sudo vi hadoop-env.sh
```

```sh
export JAVA_HOME=/lib/jvm
```

### 修改 core-site.xml

打开 core-site.xml文件并对其进行编辑，如下图所示。

```sh
vi core-site.xml
```

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node1:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/home/hadoop/hadoop-2.7.4/tmp</value>
    </property>
</configuration>
```

### 修改 hdfs-site.xml

打开hdfs-site.xml文件并对其进行编辑，如下图所示。

```sh
vi hdfs-site.xml
```

```xml
<configuration>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node1:50090</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/home/hadoop/hadoop-2.7.4/tmp/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/home/hadoop/hadoop-2.7.4/tmp/dfs/data</value>
    </property>
</configuration>
```

### 修改 mapred-site.xml

目录下么没有这个文件,这有一个模板,我们需要先拷贝一份

```sh
 cp mapred-site.xml.template mapred-site.xml
 vi mapred-site.xml
```

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>node1:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>node1:19888</value>
    </property>
</configuration>
```

### 修改 yarn-site.xml


```sh
vi yarn-site.xml
```

```xml
<configuration>
    
    <!-- Site specific YARN configuration properties -->
    
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>node1</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

## 配置集群

### 复制节点

将 hadoop-2.7.4 文件夹重打包后复制到其他子节点

```sh
cd /home/hadoop/

tar zcvf hadoop.tar.gz hadoop-2.7.4
scp hadoop.tar.gz hadoop@node2:/home/hadoop/
scp hadoop.tar.gz hadoop@node3:/home/hadoop/
```

在其他子节点 解压
```sh
tar -xzf hadoop.tar.gz
```


### 配置slaves文件

修改（Master主机）node1`/etc/hadoop/slaves`该文件指定哪些服务器节点是`datanode`节点。删除`locahost`，添加所有`datanode`节点的主机名


```sh
cd /home/hadoop/hadoop-2.7.4/etc/hadoop/

[hadoop@node1 hadoop]$ cat slaves 
node2
node3
```


# 集群操作

## Format

格式化namenode和datanode并启动，（在master上执行就可以了 不需要在slave上执行）

```sh
cd /home/hadoop/hadoop-2.7.4/bin

./hadoop namenode -format
./hadoop datanode -format
```

## 启动 hadoop

```sh
cd /home/hadoop/hadoop-2.7.4/sbin


./start-dfs.sh
./start-yarn.sh
./mr-jobhistory-daemon.sh start historyserver
```

## 查看进程服务

查看启动进程,缺少以下任一进程都表示出错

```sh
$ jps
2528 NameNode
2720 SecondaryNameNode
3190 Jps
2872 ResourceManager
3151 JobHistoryServer
```

**查看端口占用情况**

```sh
netstat -tnlp | grep java
```


访问node1

[http://192.168.252.121:50070](http://192.168.252.121:50070/)  

[http://192.168.252.121:8088](http://192.168.252.121:8088/)  


![][1]
 
![][2] 


![][3] 

## 停止 hadoop

```sh
./start-all.sh
```

或者 jps 查看进程`kill` 掉
```sh
./stop-all.sh
```

[1]: /images/2017/hadoop/tab-overview.png
[2]: /images/2017/hadoop/tab-datanode.png
[3]: /images/2017/hadoop/cluster.png

