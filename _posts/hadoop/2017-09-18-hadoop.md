---
layout: post
title: Hadoop-2.7.4 集群快速搭建
categories: Hadoop
description: Hadoop-2.7.4 集群快速搭建
keywords: Hadoop
---

# Hadoop简介

2003-2004年，Google公开了部分GFS和Mapreduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和Mapreduce机制，一个微缩版：Nutch
 
Hadoop 于 2005 年秋天作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。2006 年 3 月份，Map-Reduce 和 Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中
 
## Hadoop

**分布式存储系统HDFS （Hadoop Distributed File System ）**
- 分布式存储系统
- 提供了 高可靠性、高扩展性和高吞吐率的数据存储服务

**分布式计算框架MapReduce**
- 分布式计算框架
- 具有 易于编程、高容错性和高扩展性等优点。

## HDFS优点

**高容错性**

- 数据自动保存多个副本
- 副本丢失后，自动恢复

**适合批处理**

- 移动计算而非数据
- 数据位置暴露给计算框架

**适合大数据处理**

- GB 、TB 、甚至PB 级数据
- 百万规模以上的文件数量
- 10K+ 节点

**可构建在廉价机器上**

- 通过多副本提高可靠性
- 提供了容错和恢复 机制

## HDFS缺点

**低延迟数据访问**

- 比如毫秒级
- 低延迟与高吞吐率

**小文件存取**

- 占用NameNode 大量内存
- 寻道时间超过读取时间

**并发写入、文件随机修改**

- 一个文件只能有一个写者
- 仅支持append


# 准备工作

## 环境

```sh
JDK:1.8  
Hadoop Release:2.7.4  
centos:7.3  

node1（master）  主机: 192.168.252.121  
node2（slave1）  从机: 192.168.252.122  
node3（slave2）  从机: 192.168.252.123  
```

**安装 JDK**

[CentOs7.3 安装 JDK1.8](https://segmentfault.com/a/1190000010716919)

## 创建用户

建议创建一个单独的用户Hadoop以从Unix文件系统隔离Hadoop文件系统

```sh
$ useradd hadoop
$ passwd hadoop
New password: 
Retype new password: 
```

授权 root 权限,在`root`下面加一条`hadoop`的`hadoop  ALL=(ALL)    ALL`

```sh
$ chmod 777 /etc/sudoers
$ vi /etc/sudoers
root    ALL=(ALL)       ALL
hadoop  ALL=(ALL)       ALL
$ pkexec chmod 0440 /etc/sudoers
```

## 免秘钥登录

**SSH 免秘钥**

[CentOs7.3 Hadoop 用户 ssh 免密登录](https://segmentfault.com/a/1190000011264924)

# 安装


## 下载解压

在 ndoe1 上操作
```sh
su hadoop
cd /home/hadoop/
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.4/hadoop-2.7.4.tar.gz
tar -zxvf hadoop-2.7.4.tar.gz
```
## 环境变量

如果是对所有的用户都生效就修改`vi /etc/profile` 文件
如果只针对当前用户生效就修改 `vi ~/.bahsrc` 文件

```sh
sudo vi /etc/profile
```

```sh
#hadoop
export PATH=${HADOOP_HOME}/bin:$PATH
export HADOOP_HOME=/home/hadoop/hadoop-2.7.4/
```

使环境变量生效，运行 `source /etc/profile`使`/etc/profile`文件生效

## 配置Hadoop

进入hadoop 配置文件目录

```sh
cd /home/hadoop/hadoop-2.7.4/etc/hadoop/
```

编辑 `hadoop-env.sh` 文件,找到 `JAVA_HOME` 改为 JDK 的安装目录

```sh
sudo vi hadoop-env.sh
```

```sh
export JAVA_HOME=/lib/jvm
```

### 修改 core-site.xml

打开 core-site.xml文件并对其进行编辑，如下图所示。

```sh
vi core-site.xml
```

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node1:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/home/hadoop/hadoop-2.7.4/tmp</value>
    </property>
</configuration>
```

### 修改 hdfs-site.xml

打开hdfs-site.xml文件并对其进行编辑，如下图所示。

```sh
vi hdfs-site.xml
```

```xml
<configuration>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node1:50090</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/home/hadoop/hadoop-2.7.4/tmp/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/home/hadoop/hadoop-2.7.4/tmp/dfs/data</value>
    </property>
</configuration>
```

### 修改 mapred-site.xml

目录下么没有这个文件,这有一个模板,我们需要先拷贝一份

```sh
cp mapred-site.xml.template mapred-site.xml
vi mapred-site.xml
```

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>node1:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>node1:19888</value>
    </property>
</configuration>
```

### 修改 yarn-site.xml


```sh
vi yarn-site.xml
```

```xml
<configuration>
    
    <!-- Site specific YARN configuration properties -->
    
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>node1</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

## 配置集群

### 复制节点

将 hadoop-2.7.4 文件夹重打包后复制到其他子节点

```sh
cd /home/hadoop/

tar zcvf hadoop.tar.gz hadoop-2.7.4
scp hadoop.tar.gz hadoop@node2:/home/hadoop/
scp hadoop.tar.gz hadoop@node3:/home/hadoop/
```

在其他子节点 解压
```sh
tar -zxvf hadoop.tar.gz
```


### 配置slaves文件

修改（Master主机）node1`/etc/hadoop/slaves`该文件指定哪些服务器节点是`datanode`节点。删除`locahost`，添加所有`datanode`节点的主机名


```sh
cd /home/hadoop/hadoop-2.7.4/etc/hadoop/

[hadoop@node1 hadoop]$ cat slaves 
node2
node3
```


# 集群操作

## Format

格式化namenode和datanode并启动，（在master上执行就可以了 不需要在slave上执行）

```sh
cd /home/hadoop/hadoop-2.7.4/bin

./hadoop namenode -format
./hadoop datanode -format
```

## 启动 hadoop

关闭防火墙

```sh
systemctl stop firewalld.service
```

```sh
cd /home/hadoop/hadoop-2.7.4/sbin


./start-dfs.sh
./start-yarn.sh
./mr-jobhistory-daemon.sh start historyserver
```

或者

```sh
./start-all.sh

./mr-jobhistory-daemon.sh start historyserver
```


## 查看进程服务

查看启动进程,缺少以下任一进程都表示出错

```sh
$ jps
2528 NameNode
2720 SecondaryNameNode
2872 ResourceManager
3151 JobHistoryServer
```

**查看端口占用情况**

```sh
netstat -tnlp | grep java
```

访问node1

[http://192.168.252.121:50070](http://192.168.252.121:50070/)  

[http://192.168.252.121:8088](http://192.168.252.121:8088/)  


![](https://user-gold-cdn.xitu.io/2017/9/19/29ce34f983d424b16813b9b7fbc98bbe)

![](https://user-gold-cdn.xitu.io/2017/9/19/8517294e413d15b86576f0ff063b60b1)

![](https://user-gold-cdn.xitu.io/2017/9/19/06b9b7afbfb8438ed373c2d91709f590)
## 停止 hadoop

```sh
cd /home/hadoop/hadoop-2.7.4/sbin

./stop-all.sh
```

或者 jps 查看进程`kill` 掉

[1]: http://www.ymq.io/images/2017/hadoop/tab-overview.png
[2]: http://www.ymq.io/images/2017/hadoop/tab-datanode.png
[3]: http://www.ymq.io/images/2017/hadoop/cluster.png

# Contact

 - 作者：鹏磊  
 - 出处：[http://www.ymq.io](http://www.ymq.io)  
 - Email：[admin@souyunku.com](admin@souyunku.com)
 - 版权归作者所有，转载请注明出处
 - Wechat：关注公众号，搜云库，分享技术，分享生活
 
![关注公众号-搜云库](http://www.ymq.io/images/souyunku.png "搜云库")